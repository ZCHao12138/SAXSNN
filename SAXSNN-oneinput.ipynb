{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e295805-9499-44c3-b673-f6cc35e185c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras as kr\n",
    "from tensorflow.python.keras import backend as K\n",
    "#from skimage import io, transform, img_as_float \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '/cpu:0'\n",
    "#from tensorflow.compat.v1 import ConfigProto\n",
    "#from tensorflow.compat.v1 import InteractiveSession\n",
    "#config = ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "T = 0.5\n",
    "\n",
    "def train_id_to_path(x):\n",
    "    return 'SAXSdata/IPP/' + str(x) + \".tif\"\n",
    "#def test_id_to_path(x):\n",
    "    #return 'SAXSdata/' + x + \".tif\"\n",
    "    \n",
    "def custom_rgb_to_grayscale(image, weights):  \n",
    "    gray_image = tf.reduce_mean(tf.cast(image, tf.float32) * weights, axis=-1)  \n",
    "    return gray_image\n",
    "\n",
    "def path_to_eagertensor(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    #f = np.fft.fft2(image)\n",
    "    #fshift = np.fft.fftshift(f)\n",
    "    #magnitude_spectrum = np.log(np.abs(fshift)) \n",
    "    image = tf.cast(image, tf.float32) / 255\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    return image\n",
    "\n",
    "def path_to_eagertensor2(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    magnitude_spectrum = np.array(tf.image.rgb_to_grayscale(image))\n",
    "    image = (magnitude_spectrum - magnitude_spectrum.min()) * (1 / (magnitude_spectrum.max() - magnitude_spectrum.min()))\n",
    "    #image = cv2.normalize(image, resultimage, 0, 255, cv2.NORM_MINMAX)\n",
    "    #image = custom_rgb_to_grayscale(image, weights)\n",
    "    #f = np.fft.fft2(image)\n",
    "    #fshift = np.fft.fftshift(f)\n",
    "    #magnitude_spectrum = np.log(np.abs(fshift)) \n",
    "    #image = tf.cast(image, tf.float32) / 225\n",
    "    #image1 = tf.image.central_crop(image, 0.4)\n",
    "    #mask = tf.ones_like(image1)\n",
    "    #image1 = tf.image.resize_with_crop_or_pad(image1, image_height, image_width)\n",
    "    return image\n",
    "\n",
    "def int_to_float(image_path):\n",
    "    image = io.imread(image_path)  #读取图像为整型， [0-255]\n",
    "    image = img_as_float(image)  #变为浮点型[0-1]。\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    images = (magnitude_spectrum - magnitude_spectrum.min()) * (1 / (magnitude_spectrum.max() - magnitude_spectrum.min()))  #比例缩放的归一化\n",
    "    images = transform.resize(images, (image_height, image_width))  #图像缩放大小\n",
    "    return images\n",
    "    \n",
    "def plot_predictions(y_true, y_end, y_pred1, y_pred2):    \n",
    "    f, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    ax[0][0].imshow(np.reshape(y_true, (128, 128)), aspect='auto')\n",
    "    ax[1][0].imshow(np.reshape(y_pred1, (128, 128)), aspect='auto',cmap = 'gray')\n",
    "    ax[0][1].imshow(np.reshape(y_end, (2, 2)), aspect='auto')\n",
    "    ax[1][1].imshow(np.reshape(y_pred2, (128, 128)), aspect='auto',cmap = 'gray')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_predictions2(y_enc):  \n",
    "    f, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    plt.imshow(np.reshape(y_enc, (128, 128)), aspect='auto',cmap='gray')\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    cb=plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=20)\n",
    "    cb.ax.set_xlabel('gray', size=20,fontproperties=\"Arial\")\n",
    "    #plt.clim(0,1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('SAXSdata/IPP/1.jpg')\n",
    "    \n",
    "def ff_propagation(image):\n",
    "    #with tf.compat.v1.Session() as sess:\n",
    "    #    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    #    images = sess.run(self.outputs)\n",
    "    #print(self.outputs, type(self.outputs))\n",
    "    image = tf.cast(image, tf.complex64)\n",
    "    f = tf.signal.fft3d(image)\n",
    "    fshift = tf.signal.fftshift(f)\n",
    "    #magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "    magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "    intensity = tf.cast(magnitude_spectrum, tf.float32)\n",
    "    intensity = (intensity - tf.reduce_min(intensity)) * (1 / (tf.reduce_max(intensity) - tf.reduce_min(intensity)))\n",
    "    #intensity = tf.image.resize(intensity, (64, 64))\n",
    "    return intensity\n",
    "    \n",
    "def combine_complex(amp, phi):\n",
    "    output = tf.cast(amp, tf.complex64) * tf.exp(\n",
    "        1j * tf.cast(phi, tf.complex64))\n",
    "    return output\n",
    "\n",
    "def get_mask1(input):\n",
    "    mask = tf.where(input >= T, tf.ones_like(input),\n",
    "                    tf.zeros_like(input))\n",
    "    return mask\n",
    "    \n",
    "def get_mask2(input):\n",
    "    mask = tf.where(input < T, tf.ones_like(input),\n",
    "                    tf.zeros_like(input))\n",
    "    return mask\n",
    "\n",
    "def getdata():\n",
    "    cols = [\"id\"]\n",
    "    df = pd.read_csv(\"SAXSdata/IPP/data.dat\", sep=\" \", header=None, names=cols)\n",
    "    df[\"img_path\"] = df[\"id\"].apply(train_id_to_path)\n",
    "    X = []\n",
    "    Y = df[[\"id\"]]\n",
    "   \n",
    "    for img in df['img_path']:\n",
    "        new_img_tensor = path_to_eagertensor2(img)\n",
    "        X.append(new_img_tensor)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    print(type(X),X.shape)\n",
    "    print(type(Y),Y.shape)\n",
    "    x_train = X\n",
    "    y_train = Y\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state=42)\n",
    "    print(type(x_train),x_train.shape)\n",
    "    print(type(y_train),y_train.shape)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edffad-71cb-44af-a7fe-5a9e3d27528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(kr.callbacks.Callback):\n",
    "    def _init_(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "        \n",
    "class checkpointCallback(kr.callbacks.Callback):\n",
    "    def _init_(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.logs=[]\n",
    "        self.save_freq = 50\n",
    "        self._epoches_seen_since_last_saving = 0\n",
    "        self._last_epoch_seen = 0\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "        \n",
    "    def _should_save_on_batch(self, epoch):\n",
    "        \"\"\"Handles batch-level saving logic, supports steps_per_execution.\"\"\"\n",
    "        if epoch <= self._last_epoch_seen:  # New epoch.\n",
    "            add_batches = epoch + 1  # batches are zero-indexed.\n",
    "        else:\n",
    "            add_batches = epoch - self._last_epoch_seen\n",
    "        self._epoches_seen_since_last_saving += add_batches\n",
    "        self._last_epoch_seen = epoch\n",
    "\n",
    "        if self._epoches_seen_since_last_saving >= self.save_freq:\n",
    "            self._epoches_seen_since_last_saving = 0\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "        #self.model.predict(y_true)\n",
    "        if self._should_save_on_batch(epoch):\n",
    "            y_pred2 = end.decoder().predict(y_true)\n",
    "            plt.imsave('SAXSdata/IPP/1/1-' + str(sum(self.logs)) + '.jpg', np.reshape(y_pred2, (128, 128)), cmap='gray')\n",
    "    \n",
    "cb = checkpointCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade46eb6-6608-4667-8321-55f4282507a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAED2():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_dim = (128,128,1)\n",
    "        self.input_latent = 128*128\n",
    "        self.latent_dim = 64\n",
    "        \n",
    "        self.inputs = kr.Input(shape=self.input_dim)        \n",
    "        # generate latent vector Q(z|X)\n",
    "        x = kr.layers.Conv2D(64, (3, 3), strides=2, padding='same')(self.inputs)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(32, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(16, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(1, (3, 3), strides=1, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "\n",
    "        #x = kr.layers.Dense(16, activation='relu')(x)\n",
    "        self.z_mean = x\n",
    "        #self.z_log_var = kr.layers.Dense(self.latent_dim)(x)\n",
    "        #self.z = kr.layers.Lambda(self.sampling, output_shape=(self.latent_dim,))([self.z_mean, self.z_log_var])\n",
    "        \n",
    "        # build decoder model\n",
    "        #latent_inputs = kr.Input(shape=(latent_dim,), name='z_sampling')\n",
    "        #self.dec1 = kr.layers.Dense(64, activation='relu')\n",
    "        #x = kr.layers.Dense(64, activation='relu')(self.z_mean)\n",
    "        x = kr.layers.Conv2DTranspose(16, (3, 3), strides=2, padding='same')(self.z_mean)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(16, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(64, (3, 3), strides=1, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        #x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        #x = kr.layers.Conv2DTranspose(64, (3, 3), strides=1, padding='same')(x)\n",
    "        #x = kr.activations.relu(x,alpha=0.05)\n",
    "        #x = kr.layers.BatchNormalization()(x)\n",
    "        #x = kr.layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same')(x)\n",
    "        #x = kr.activations.relu(x,alpha=0.05)\n",
    "        #x = kr.layers.BatchNormalization()(x)\n",
    "        self.dec_out = kr.layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "        \n",
    "        # forward propagation\n",
    "        # far-field propagation to get the diff\n",
    "        self.Psi = kr.layers.Lambda(lambda x: ff_propagation(x), name='farfield_diff')(self.dec_out)\n",
    "        \n",
    "        #x = kr.layers.Resizing(64,64)(self.Psi)\n",
    "        \n",
    "        self.outputs = self.Psi \n",
    "        \n",
    "    # sampling function\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        nd = K.shape(z_mean)[0]\n",
    "        nc = self.latent_dim\n",
    "        eps = K.random_normal(shape=(nd, nc), mean=0., stddev=1.0)\n",
    "        return z_mean + K.exp(z_log_var / 2) * eps\n",
    "\n",
    "    def vae(self):\n",
    "        return kr.Model(self.inputs, self.outputs)\n",
    "    \n",
    "    def encoder(self):\n",
    "        return kr.Model(self.inputs, self.z_mean)\n",
    "    \n",
    "    def decoder(self): \n",
    "        return kr.Model(self.inputs, self.dec_out)\n",
    "\n",
    "    def loss(self):\n",
    "        mse = kr.metrics.binary_crossentropy(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        xent_loss = self.input_latent * mse\n",
    "        kl = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "        kl_loss = - 0.5 * K.sum(kl, axis=-1)\n",
    "        vae_loss = K.mean(xent_loss + kl_loss)\n",
    "        return vae_loss\n",
    "    \n",
    "    def loss2(self):\n",
    "        #with tf.compat.v1.Session() as sess:\n",
    "        #    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        #    images = sess.run(self.outputs)\n",
    "        #print(self.outputs, type(self.outputs))\n",
    "        image1 = tf.cast(self.outputs, tf.complex64)\n",
    "        f = tf.signal.fft2d(image1)\n",
    "        fshift = tf.signal.fftshift(f)\n",
    "        magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "        spectrum = tf.cast(magnitude_spectrum, tf.float32)\n",
    "        spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mse = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(spectrum))\n",
    "        xent_loss = self.input_latent * mse\n",
    "        return xent_loss\n",
    "    \n",
    "    def loss3(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mae = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(tf.cast(tf.math.log(tf.math.abs(tf.signal.fftshift(tf.signal.fft2d(tf.cast(self.outputs, tf.complex64))))), tf.float32)))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mae\n",
    "    \n",
    "    def loss4(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mse = kr.metrics.mean_squared_error(K.flatten(self.inputs), K.flatten(tf.cast(tf.math.log(tf.math.abs(tf.signal.fftshift(tf.signal.fft2d(tf.cast(self.outputs, tf.complex64))))), tf.float32)))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mse\n",
    "    \n",
    "    def loss5(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mae = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mae\n",
    "    \n",
    "    def loss_pcc(self):\n",
    "        pred = self.outputs - tf.reduce_mean(self.outputs,axis=(1,2),keepdims=True)\n",
    "        true = self.inputs - tf.reduce_mean(self.inputs,axis=(1,2),keepdims=True)\n",
    "        top = tf.reduce_sum(pred * true,axis=(1,2),keepdims=True)\n",
    "    \n",
    "        pred_sum = tf.reduce_sum(pred*pred,axis=(1,2),keepdims=True)\n",
    "        true_sum = tf.reduce_sum(true*true,axis=(1,2),keepdims=True)\n",
    "        bottom = tf.math.sqrt(pred_sum * true_sum)\n",
    "    \n",
    "        loss_value = tf.reduce_sum(1 - top / bottom)\n",
    "        return loss_value\n",
    "    \n",
    "    def loss_comb(self):  \n",
    "        pred = self.outputs - tf.reduce_mean(self.outputs,axis=(1,2),keepdims=True)\n",
    "        true = self.inputs - tf.reduce_mean(self.inputs,axis=(1,2),keepdims=True)\n",
    "        top = tf.reduce_sum(pred * true,axis=(1,2),keepdims=True)\n",
    "    \n",
    "        pred_sum = tf.reduce_sum(pred*pred,axis=(1,2),keepdims=True)\n",
    "        true_sum = tf.reduce_sum(true*true,axis=(1,2),keepdims=True)\n",
    "        bottom = tf.math.sqrt(pred_sum * true_sum)\n",
    "        loss_1 = tf.reduce_sum(1 - top / bottom)\n",
    "        loss_2 = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        a1 = 1\n",
    "        a2 = 1\n",
    "        loss_value = (a1*loss_1+a2*loss_2)/(a1+a2)\n",
    "        return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602c1f6-a207-4dd2-9a17-1e61dcdadf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf.compat.v1.enable_eager_execution()\n",
    "x_train, y_train = getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582aba9-64da-4902-b272-fe7ed326108b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = x_train[0:1]\n",
    "#y_true = end.encoder0().predict(y_true)\n",
    "def show_train_image(y_true):  \n",
    "    f, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    plt.imshow(np.reshape(y_true, (128, 128)), aspect='auto',cmap = 'gray')\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    cb=plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=20)\n",
    "    cb.ax.set_xlabel('gray', size=20,fontproperties=\"Arial\")\n",
    "    plt.clim(0,1)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('saxsGH/test4/intens.jpg')\n",
    "show_train_image(y_true)\n",
    "#plt.imsave('saxsGH/4/intens.jpg', np.reshape(y_true, (128, 128)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca81093-5770-47b8-8c0a-f2e4a04b1bdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "seed = 42\n",
    "batch_size = 1\n",
    "epochs = 8000\n",
    "\n",
    "np.random.seed(seed)\n",
    "end = VAED2()\n",
    "model = end.vae()\n",
    "model.summary()\n",
    "model.add_loss(end.loss_pcc())\n",
    "\n",
    "np.random.seed(seed)\n",
    "#adam = kr.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=kr.optimizers.Adam(lr = 0.00005, decay=0.0004), loss=None)\n",
    "#history = model.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data = (y_train,None))\n",
    "history = model.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254038a-f502-4c3f-a1a6-c4a1a528abe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "ax=plt.gca()\n",
    "ax.spines['top'].set_linewidth(1)\n",
    "ax.spines['bottom'].set_linewidth(1)\n",
    "ax.spines['left'].set_linewidth(1)\n",
    "ax.spines['right'].set_linewidth(1)\n",
    "#plt.grid(linestyle=\"--\")\n",
    "#plt.plot(loss00001, label=\"Training Loss\", linewidth=2)\n",
    "plt.plot(history.history[\"loss\"], label=\"η = 5×10$^{-5}$\", linewidth=2.5)\n",
    "#plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xticks(fontsize = 20, fontweight='bold')\n",
    "plt.yticks(fontsize = 20, fontweight='bold')\n",
    "plt.xlabel(\"Epochs\",fontsize = 25,fontproperties=\"Arial\",fontweight='bold')\n",
    "plt.ylabel(\"1+NPCC\",fontsize = 25,fontproperties=\"Arial\",fontweight='bold')\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(-0.01,0.75)\n",
    "plt.legend()\n",
    "leg = plt.gca().get_legend()\n",
    "ltext = leg.get_texts()\n",
    "plt.setp(ltext, fontsize = 20,fontweight='bold')\n",
    "#plt.savefig('saxsGH/test4/1loss0.00005-0.0004.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01782eb8-5c6d-446f-9017-f0b647818427",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = x_train[0:1]\n",
    "y_enc = end.encoder().predict(y_true)\n",
    "y_pred1 = model.predict(y_true)\n",
    "y_pred2 = end.decoder().predict(y_true)\n",
    "#y_true = end.encoder0().predict(y_true)\n",
    "plot_predictions(y_true, y_enc, y_pred1, y_pred2)\n",
    "#plt.imsave('saxsGH/test4/sem2-1.jpg', np.reshape(y_pred2, (128, 128)), cmap='gray')\n",
    "#plt.imsave('saxsGH/test4/saxs1gray.jpg', np.reshape(y_pred1, (128, 128)), cmap='gray')\n",
    "#plt.imsave('saxsGH/test4/saxs1.jpg', np.reshape(y_pred1, (128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51daf3-378c-4584-a21e-781c77214cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = x_train[0:1]\n",
    "y_enc = end.encoder().predict(y_true)\n",
    "plot_predictions2(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb32c36-bb12-4b53-99b5-55be975d2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the predicted results during the calculation process while iterating\n",
    "epochs = 2000\n",
    "np.random.seed(seed)\n",
    "end = VAED2()\n",
    "model = end.vae()\n",
    "model.summary()\n",
    "model.add_loss(end.loss_pcc())\n",
    "#adam = kr.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=kr.optimizers.Adam(lr = 0.00005), loss=None)\n",
    "#history = model.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data = (y_train,None))\n",
    "history = model.fit(x_train, epochs=epochs, batch_size=batch_size, callbacks=[cb])\n",
    "plt.cla()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

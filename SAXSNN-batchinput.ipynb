{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495d80d-d765-477a-ad24-5b7552b05f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras as kr\n",
    "from tensorflow.python.keras import backend as K\n",
    "from timeit import default_timer as timer\n",
    "#from skimage import io, transform, img_as_float \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '/cpu:0'\n",
    "#from tensorflow.compat.v1 import ConfigProto\n",
    "#from tensorflow.compat.v1 import InteractiveSession\n",
    "#config = ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "\n",
    "def train_id_to_path(x):\n",
    "    return 'SAXSdata/UHMWPE/' + str(x) + \".tif\"\n",
    "    #return 'SAXSdata/' + x + \".tif\"\n",
    "    \n",
    "def custom_rgb_to_grayscale(image, weights):  \n",
    "    gray_image = tf.reduce_mean(tf.cast(image, tf.float32) * weights, axis=-1)  \n",
    "    return gray_image\n",
    "\n",
    "def path_to_eagertensor(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    #f = np.fft.fft2(image) \n",
    "    #fshift = np.fft.fftshift(f)\n",
    "    #magnitude_spectrum = np.log(np.abs(fshift)) \n",
    "    image = tf.cast(image, tf.float32) / 255\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    return image\n",
    "\n",
    "def path_to_eagertensor2(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    magnitude_spectrum = np.array(tf.image.rgb_to_grayscale(image))\n",
    "    image = (magnitude_spectrum - magnitude_spectrum.min()) * (1 / (magnitude_spectrum.max() - magnitude_spectrum.min()))\n",
    "    #image = cv2.normalize(image, resultimage, 0, 255, cv2.NORM_MINMAX)\n",
    "    #image = custom_rgb_to_grayscale(image, weights)\n",
    "    #f = np.fft.fft2(image)\n",
    "    #fshift = np.fft.fftshift(f)\n",
    "    #magnitude_spectrum = np.log(np.abs(fshift)) \n",
    "    #image = tf.cast(image, tf.float32) / 225\n",
    "    #image1 = tf.image.central_crop(image, 0.4)\n",
    "    #mask = tf.ones_like(image1)\n",
    "    #image1 = tf.image.resize_with_crop_or_pad(image1, image_height, image_width)\n",
    "    return image\n",
    "\n",
    "def int_to_float(image_path):\n",
    "    image = io.imread(image_path)  #读取图像为整型， [0-255]\n",
    "    image = img_as_float(image)  #变为浮点型[0-1]。\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    images = (magnitude_spectrum - magnitude_spectrum.min()) * (1 / (magnitude_spectrum.max() - magnitude_spectrum.min()))  #比例缩放的归一化\n",
    "    images = transform.resize(images, (image_height, image_width))  #图像缩放大小\n",
    "    return images\n",
    "\n",
    "def plot_predictions(y_true, y_pred):    \n",
    "    f, ax = plt.subplots(2, 5, figsize=(30, 10))\n",
    "    for i in range(5):\n",
    "        ax[0][i].imshow(np.reshape(y_true[i], (64, 64)), aspect='auto')\n",
    "        ax[1][i].imshow(np.reshape(y_pred[i], (64, 64)), aspect='auto')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def ff_propagation(image):\n",
    "    #with tf.compat.v1.Session() as sess:\n",
    "    #    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    #    images = sess.run(self.outputs)\n",
    "    #print(self.outputs, type(self.outputs))\n",
    "    image = tf.cast(image, tf.complex64)\n",
    "    f = tf.signal.fft3d(image)\n",
    "    fshift = tf.signal.fftshift(f)\n",
    "    #magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "    magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "    intensity = tf.cast(magnitude_spectrum, tf.float32) / 255\n",
    "    #intensity = tf.image.resize(intensity, (64, 64))\n",
    "    return intensity\n",
    "    \n",
    "def combine_complex(amp, phi):\n",
    "    output = tf.cast(amp, tf.complex64) * tf.exp(\n",
    "        1j * tf.cast(phi, tf.complex64))\n",
    "    return output\n",
    "\n",
    "def get_mask1(input):\n",
    "    mask = tf.where(input >= T, tf.ones_like(input),\n",
    "                    tf.zeros_like(input))\n",
    "    return mask\n",
    "    \n",
    "def get_mask2(input):\n",
    "    mask = tf.where(input < T, tf.ones_like(input),\n",
    "                    tf.zeros_like(input))\n",
    "    return mask\n",
    "\n",
    "def getdata():\n",
    "    cols = [\"id\"]\n",
    "    df = pd.read_csv(\"SAXSdata/UHMWPE/data.dat\", sep=\" \", header=None, names=cols)\n",
    "    df[\"img_path\"] = df[\"id\"].apply(train_id_to_path)\n",
    "    X = []\n",
    "    Y = df[[\"id\"]]\n",
    "   \n",
    "    for img in df['img_path']:\n",
    "        new_img_tensor = path_to_eagertensor2(img)\n",
    "        X.append(new_img_tensor)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    print(type(X),X.shape)\n",
    "    print(type(Y),Y.shape)\n",
    "    x_train = X\n",
    "    y_train = Y\n",
    "    print(type(x_train),x_train.shape)\n",
    "    print(type(y_train),y_train.shape)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0b310-9bbf-4b65-88e2-a0aaa4f36f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAED2():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_dim = (128,128,1)\n",
    "        self.input_latent = 128*128\n",
    "        self.latent_dim = 64\n",
    "        \n",
    "        self.inputs = kr.Input(shape=self.input_dim)        \n",
    "        # generate latent vector Q(z|X)\n",
    "        x = kr.layers.Conv2D(64, (3, 3), strides=2, padding='same')(self.inputs)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(32, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(16, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.MaxPooling2D((2, 2))(x)\n",
    "        x = kr.layers.Conv2D(1, (3, 3), strides=1, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "\n",
    "        #x = kr.layers.Dense(16, activation='relu')(x)\n",
    "        self.z_mean = x\n",
    "        #self.z_log_var = kr.layers.Dense(self.latent_dim)(x)\n",
    "        #self.z = kr.layers.Lambda(self.sampling, output_shape=(self.latent_dim,))([self.z_mean, self.z_log_var])\n",
    "        \n",
    "        # build decoder model\n",
    "        #latent_inputs = kr.Input(shape=(latent_dim,), name='z_sampling')\n",
    "        #self.dec1 = kr.layers.Dense(64, activation='relu')\n",
    "        #x = kr.layers.Dense(64, activation='relu')(self.z_mean)\n",
    "        x = kr.layers.Conv2DTranspose(16, (3, 3), strides=2, padding='same')(self.z_mean)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(16, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        x = kr.layers.Conv2DTranspose(64, (3, 3), strides=1, padding='same')(x)\n",
    "        x = kr.activations.relu(x,alpha=0.05)\n",
    "        x = kr.layers.BatchNormalization()(x)\n",
    "        #x = kr.layers.UpSampling2D((2,2))(x)\n",
    "        #x = kr.layers.Conv2DTranspose(64, (3, 3), strides=1, padding='same')(x)\n",
    "        #x = kr.activations.relu(x,alpha=0.05)\n",
    "        #x = kr.layers.BatchNormalization()(x)\n",
    "        #x = kr.layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same')(x)\n",
    "        #x = kr.activations.relu(x,alpha=0.05)\n",
    "        #x = kr.layers.BatchNormalization()(x)\n",
    "        self.dec_out = kr.layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "        \n",
    "        # forward propagation\n",
    "        # far-field propagation to get the diff\n",
    "        self.Psi = kr.layers.Lambda(lambda x: ff_propagation(x), name='farfield_diff')(self.dec_out)\n",
    "        \n",
    "        #x = kr.layers.Resizing(64,64)(self.Psi)\n",
    "        \n",
    "        self.outputs = self.Psi \n",
    "        \n",
    "    # sampling function\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        nd = K.shape(z_mean)[0]\n",
    "        nc = self.latent_dim\n",
    "        eps = K.random_normal(shape=(nd, nc), mean=0., stddev=1.0)\n",
    "        return z_mean + K.exp(z_log_var / 2) * eps\n",
    "\n",
    "    def vae(self):\n",
    "        return kr.Model(self.inputs, self.outputs)\n",
    "    \n",
    "    def encoder(self):\n",
    "        return kr.Model(self.inputs, self.z_mean)\n",
    "    \n",
    "    def decoder(self): \n",
    "        return kr.Model(self.inputs, self.dec_out)\n",
    "\n",
    "    def loss(self):\n",
    "        mse = kr.metrics.binary_crossentropy(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        xent_loss = self.input_latent * mse\n",
    "        kl = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "        kl_loss = - 0.5 * K.sum(kl, axis=-1)\n",
    "        vae_loss = K.mean(xent_loss + kl_loss)\n",
    "        return vae_loss\n",
    "    \n",
    "    def loss2(self):\n",
    "        #with tf.compat.v1.Session() as sess:\n",
    "        #    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        #    images = sess.run(self.outputs)\n",
    "        #print(self.outputs, type(self.outputs))\n",
    "        image1 = tf.cast(self.outputs, tf.complex64)\n",
    "        f = tf.signal.fft2d(image1)\n",
    "        fshift = tf.signal.fftshift(f)\n",
    "        magnitude_spectrum = tf.math.log(tf.math.abs(fshift))\n",
    "        spectrum = tf.cast(magnitude_spectrum, tf.float32)\n",
    "        spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mse = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(spectrum))\n",
    "        xent_loss = self.input_latent * mse\n",
    "        return xent_loss\n",
    "    \n",
    "    def loss3(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mae = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(tf.cast(tf.math.log(tf.math.abs(tf.signal.fftshift(tf.signal.fft2d(tf.cast(self.outputs, tf.complex64))))), tf.float32)))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mae\n",
    "    \n",
    "    def loss4(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mse = kr.metrics.mean_squared_error(K.flatten(self.inputs), K.flatten(tf.cast(tf.math.log(tf.math.abs(tf.signal.fftshift(tf.signal.fft2d(tf.cast(self.outputs, tf.complex64))))), tf.float32)))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mse\n",
    "    \n",
    "    def loss5(self):\n",
    "        #spectrum = tf.image.resize(spectrum, (64, 64))\n",
    "        mae = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        #xent_loss = self.input_latent * mse\n",
    "        return mae\n",
    "    \n",
    "    def loss_pcc(self):\n",
    "        pred = self.outputs - tf.reduce_mean(self.outputs,axis=(1,2),keepdims=True)\n",
    "        true = self.inputs - tf.reduce_mean(self.inputs,axis=(1,2),keepdims=True)\n",
    "        top = tf.reduce_sum(pred * true,axis=(1,2),keepdims=True)\n",
    "    \n",
    "        pred_sum = tf.reduce_sum(pred*pred,axis=(1,2),keepdims=True)\n",
    "        true_sum = tf.reduce_sum(true*true,axis=(1,2),keepdims=True)\n",
    "        bottom = tf.math.sqrt(pred_sum * true_sum)\n",
    "    \n",
    "        loss_value = tf.reduce_sum(1 - top / bottom)\n",
    "        return loss_value\n",
    "    \n",
    "    def loss_comb(self):  \n",
    "        pred = self.outputs - tf.reduce_mean(self.outputs,axis=(1,2),keepdims=True)\n",
    "        true = self.inputs - tf.reduce_mean(self.inputs,axis=(1,2),keepdims=True)\n",
    "        top = tf.reduce_sum(pred * true,axis=(1,2),keepdims=True)\n",
    "    \n",
    "        pred_sum = tf.reduce_sum(pred*pred,axis=(1,2),keepdims=True)\n",
    "        true_sum = tf.reduce_sum(true*true,axis=(1,2),keepdims=True)\n",
    "        bottom = tf.math.sqrt(pred_sum * true_sum)\n",
    "        loss_1 = tf.reduce_sum(1 - top / bottom)\n",
    "        loss_2 = kr.metrics.mean_absolute_error(K.flatten(self.inputs), K.flatten(self.outputs))\n",
    "        a1 = 1\n",
    "        a2 = 1\n",
    "        loss_value = (a1*loss_1+a2*loss_2)/(a1+a2)\n",
    "        return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb4462-dc51-4cdf-a785-b9d9bd4eb91b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train = getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62c5d2-a810-4605-84bd-9754d0beab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = x_train[0:1]\n",
    "#y_true = end.encoder0().predict(y_true)\n",
    "def show_train_image(y_true):  \n",
    "    f, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    plt.imshow(np.reshape(y_true, (128, 128)), aspect='auto')\n",
    "    plt.xticks(fontsize = 15)\n",
    "    plt.yticks(fontsize = 15)\n",
    "    cb=plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=15)\n",
    "    cb.ax.set_xlabel('intensity', size=18,fontproperties=\"Arial\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('SAXSdata/UHMWPE/1/img-' + str(Y[0][0]) + '.jpg')\n",
    "show_train_image(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa531448-d406-4ff5-9677-17a29d7b948e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "seed = 0\n",
    "batch_size = 1\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3b8fc-30e3-41ea-9b48-3aad4a345303",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    y_true = x_train[i:i+1]\n",
    "    #show_train_image(y_true)\n",
    "    np.random.seed(seed)\n",
    "    end = VAED2()\n",
    "    model = end.vae()\n",
    "    model.summary()\n",
    "    model.add_loss(end.loss_pcc())\n",
    "    #adam = kr.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=kr.optimizers.Adam(lr = 0.00005), loss=None)\n",
    "    #history = model.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data = (y_train,None))\n",
    "    history = model.fit(x_train[i:i+1], epochs=epochs, batch_size=batch_size,verbose=0)\n",
    "    plt.cla()\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig('SAXSdata/UHMWPE/1/loss-' + str(Y[i][0]) + '.jpg')\n",
    "    #y_true = x_train[i:i+1]\n",
    "    y_enc = end.encoder().predict(y_true)\n",
    "    y_pred1 = model.predict(y_true)\n",
    "    y_pred2 = end.decoder().predict(y_true)\n",
    "    #y_true = end.encoder0().predict(y_true)\n",
    "    #plot_predictions6(y_true, y_enc, y_pred1, y_pred2)\n",
    "    plt.imsave('SAXSdata/UHMWPE/1/sem-' + str(Y[i][0]) + '.jpg', np.reshape(y_pred2, (128, 128)), cmap='gray')\n",
    "    plt.imsave('SAXSdata/UHMWPE/1/saxs-' + str(Y[i][0]) + '.jpg', np.reshape(y_pred1, (128, 128)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
